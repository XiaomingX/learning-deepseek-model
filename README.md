# use-deepseek-py  
ğŸ”¥ ä½¿ç”¨ DeepSeek æ„å»ºå¤§æ¨¡å‹åº”ç”¨çš„ Python å·¥å…·åŒ…  

## ğŸš€ å¿«é€Ÿå¼€å§‹

## ğŸ“Š æ¨¡å‹é€‰å‹æŒ‡å—
### æ€§èƒ½å¯¹æ¯”è¡¨
| æ¨¡å‹åç§°                  | å‚æ•°é‡ | ä¸Šä¸‹æ–‡é•¿åº¦ | é€‚ç”¨åœºæ™¯          | æ¨ç†é€Ÿåº¦ (tokens/s) |  
|--------------------------|--------|------------|-------------------|---------------------|  
| deepseek-v3-base         | 671B   | 128k       | ä»£ç ç”Ÿæˆ/æ•°æ®åˆ†æ  | 320 (A100)          |  
| deepseek-r1-32b-distill  | 32B    | 64k        | æ•°å­¦æ¨ç†/é€»è¾‘æ¨å¯¼  | 580 (RTX 4090)      |  
| deepseek-r1-zero         | 37B    | 128k       | å¤šè½®å¯¹è¯/åˆ›æ„å†™ä½œ  | 420 (A100)          |  

ğŸ’¡ å»ºè®®æ­é… vLLM æ¨ç†æ¡†æ¶å®ç°ååé‡ä¼˜åŒ–

## ğŸ› ï¸ è¿›é˜¶åŠŸèƒ½
### API å¯¹æ¥
```python
import os
from deepseek import DeepSeekAPI

client = DeepSeekAPI(
    api_key=os.getenv("DEEPSEEK_KEY"),
    base_url="https://api.deepseek.com/v1"
)

# å¸¦æ€ç»´é“¾çš„å¤æ‚æ¨ç†
response = client.chat.completions.create(
    model="deepseek-reasoner",
    messages=[{"role": "user", "content": "è¯æ˜å‹¾è‚¡å®šç†"}],
    temperature=0.7,
    reasoning_depth=2  # å¯ç”¨äºŒçº§æ¨ç†éªŒè¯
)
print(response.choices[0].message.reasoning_content)  # æ˜¾ç¤ºéªŒè¯è¿‡ç¨‹
```

### æœ¬åœ°éƒ¨ç½²ä¼˜åŒ–
```yaml
# config.yaml
compute:
  precision: bfloat16
  parallelism:
    tensor: 2
    pipeline: 4
optimization:
  flash_attention: true
  continuous_batching: true  
quantization:
  enabled: true
  method: awq
```

## ğŸŒŸ æ ¸å¿ƒä¼˜åŠ¿
### æŠ€æœ¯åˆ›æ–°
- **åŠ¨æ€ä¸“å®¶é€‰æ‹©**ï¼šä»…æ¿€æ´» 37B/671B å‚æ•°ï¼Œé™ä½ 95% è®¡ç®—æˆæœ¬ 
- **å¤šæ¨¡æ€æ³¨æ„åŠ›**ï¼šMLA æœºåˆ¶æå‡é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›ï¼ˆ128k tokensï¼‰ 
- **å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–**ï¼šGRPO ç®—æ³•å¢å¼ºæ¨ç†èƒ½åŠ›

### å¼€æºç”Ÿæ€
```mermaid
graph TD
    A[DeepSeek æ¨¡å‹] --> B(ä»£ç ç”Ÿæˆ)
    A --> C(æ•°æ®åˆ†æ)
    A --> D(æ•°å­¦è¯æ˜)
    B --> E[VSCode æ’ä»¶]
    C --> F[Pandas æ‰©å±•]
    D --> G[Lean4 é›†æˆ]
```

## ğŸ† æ€§èƒ½åŸºå‡†
| æµ‹è¯•é›†         | DeepSeek-R1 | GPT-4 | æå‡å¹…åº¦ |  
|----------------|-------------|-------|---------|  
| HumanEval      | 73.78%      | 67%   | +10%    |  
| GSM8K          | 84.1%       | 80%   | +5%     |  
| MATH-500       | 68.3%       | 65%   | +5%     |  
| è®­ç»ƒèƒ½è€— (PFLOPs)| 2.8M        | 12M   | -76%    |  

æ•°æ®æ¥æºï¼šDeepSeek æŠ€æœ¯ç™½çš®ä¹¦

## ğŸ›¡ï¸ æœ€ä½³å®è·µ
1. **æˆæœ¬æ§åˆ¶**  
```python
# å¯ç”¨åŠ¨æ€æ‰¹å¤„ç†
model.set_optimization(
    max_batch_size=32,
    memory_utilization=0.85
)
```
2. **é”™è¯¯å¤„ç†**  
```python
try:
    response = model.generate(...)
except DeepSeekError as e:
    if "rate_limit" in str(e):
        print("è§¦å‘é™æµï¼Œè‡ªåŠ¨é‡è¯•ä¸­...")
        time.sleep(1)
        response = model.generate(...)
```

3. **æ€§èƒ½ç›‘æ§**  
```bash
deepseek-monitor --model deepseek-r1 --metrics latency throughput error_rate
```

*æœ¬é¡¹ç›®çš„æ¨¡å‹æƒé‡éµå¾ª DeepSeek ç¤¾åŒºè®¸å¯åè®®ï¼Œå•†ä¸šä½¿ç”¨éœ€éµå®ˆ[é™„åŠ æ¡æ¬¾](https://www.deepseek.com/license)*
